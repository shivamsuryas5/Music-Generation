{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing basic libraries for music generation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import msgpack\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tqdm import tqdm\n",
    "import midi_manipulation\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function helps to get the path for the music genre and those songs are processed \n",
    "def get_songs(path):\n",
    "    files = glob.glob('{}/*.mid'.format(path))\n",
    "    songs = []\n",
    "    for f in tqdm(files):\n",
    "        try:\n",
    "            song = np.array(midi_manipulation.midiToNoteStateMatrix(f))\n",
    "            if np.array(song).shape[0] > 50:\n",
    "                songs.append(song)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:34<00:00,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 songs processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "songs = get_songs('Classical/')  # Give the location of genre for which user want to generate its music\n",
    "print(\"{} songs processed\".format(len(songs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_note = midi_manipulation.lowerBound              # the index of the lowest note on the piano roll\n",
    "highest_note = midi_manipulation.upperBound             # the index of the highest note on the piano roll\n",
    "note_range = highest_note - lowest_note                 # the note range\n",
    "\n",
    "num_timesteps = 15                                      # This is the number of timesteps that we will create at a time\n",
    "n_visible = 2*note_range*num_timesteps                  # This is the size of the visible layer.\n",
    "n_hidden = 50                                           # This is the size of the hidden layer\n",
    "\n",
    "num_epochs = 200                                        # The number of training epochs that we are going to run.\n",
    "\n",
    "batch_size = 100                                        # The number of training examples that we are going to send through the RBM at a time.\n",
    "\n",
    "lr = tf.constant(0.005, tf.float32)                     # The learning rate of our model\n",
    "\n",
    "# Variables:\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_visible], name=\"x\") # The placeholder variable that holds our data\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_visible, n_hidden], 0.01), name=\"W\")  # The weight matrix that stores the edge weights\n",
    "\n",
    "bh = tf.Variable(tf.zeros([1, n_hidden], tf.float32, name=\"bh\"))  # The bias vector for the hidden layer\n",
    "\n",
    "bv = tf.Variable(tf.zeros([1, n_visible], tf.float32, name=\"bv\")) # The bias vector for the visible layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(probs):\n",
    "    # Takes in a vector of probabilities, and returns a random vector of 0s and 1s sampled from the input vector\n",
    "    return tf.floor(probs + tf.random_uniform(tf.shape(probs), 0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sample(k):\n",
    "   \n",
    "    def gibbs_step(count, k, xk):\n",
    "        \n",
    "        hk = sample(tf.sigmoid(tf.matmul(xk, W) + bh))  # Propagate the visible values to sample the hidden values\n",
    "        xk = sample(\n",
    "            tf.sigmoid(tf.matmul(hk, tf.transpose(W)) + bv))  # Propagate the hidden values to sample the visible values\n",
    "        return count + 1, k, xk\n",
    "\n",
    "    # Run gibbs steps for k iterations\n",
    "    ct = tf.constant(0)  # counter\n",
    "    [_, _, x_sample] = control_flow_ops.while_loop(lambda count, num_iter, *args: count < num_iter,\n",
    "                                                   gibbs_step, [ct, tf.constant(k), x])\n",
    "    # This is not strictly necessary in this implementation, but if you want to adapt this code to use one of TensorFlow's optimizers, you need this in order to stop tensorflow from propagating gradients back through the gibbs step\n",
    "    x_sample = tf.stop_gradient(x_sample)\n",
    "    return x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Code\n",
    "# Now we implement the contrastive divergence algorithm. First, we get the samples of x and h from the probability distribution\n",
    "# The sample of x\n",
    "x_sample = gibbs_sample(1)\n",
    "\n",
    "# The sample of the hidden nodes, starting from the visible state of x\n",
    "h = sample(tf.sigmoid(tf.matmul(x, W) + bh))\n",
    "\n",
    "# The sample of the hidden nodes, starting from the visible state of x_sample\n",
    "h_sample = sample(tf.sigmoid(tf.matmul(x_sample, W) + bh))\n",
    "\n",
    "# Next, we update the values of W, bh, and bv,\n",
    "# based on the difference between the samples that we drew and the original values\n",
    "size_bt = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "W_adder = tf.multiply(lr / size_bt,\n",
    "                      tf.subtract(tf.matmul(tf.transpose(x), h), tf.matmul(tf.transpose(x_sample), h_sample)))\n",
    "bv_adder = tf.multiply(lr / size_bt, tf.reduce_sum(tf.subtract(x, x_sample), 0, True))\n",
    "bh_adder = tf.multiply(lr / size_bt, tf.reduce_sum(tf.subtract(h, h_sample), 0, True))\n",
    "\n",
    "# When we do sess.run(updt), TensorFlow will run all 3 update steps\n",
    "updt = [W.assign_add(W_adder), bv.assign_add(bv_adder), bh.assign_add(bh_adder)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [01:53<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # First, we train the model\n",
    "    # initialize the variables of the model\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    # Run through all of the training data num_epochs times\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for song in songs:\n",
    "            # The songs are stored in a time x notes format. The size of each song is timesteps_in_song x 2*note_range\n",
    "            # Here we reshape the songs so that each training example\n",
    "            # is a vector with num_timesteps x 2*note_range elements\n",
    "            song = np.array(song)\n",
    "            song = song[:int(np.floor(song.shape[0] // num_timesteps) * num_timesteps)]\n",
    "            song = np.reshape(song, [song.shape[0] // num_timesteps, song.shape[1] * num_timesteps])\n",
    "            \n",
    "            # Train the RBM on batch_size examples at a time\n",
    "            for i in range(1, len(song), batch_size):\n",
    "                tr_x = song[i:i + batch_size]\n",
    "                sess.run(updt, feed_dict={x: tr_x})\n",
    "\n",
    "    # Now the model is fully trained.\n",
    "    # Run a gibbs chain where the visible nodes are initialized to 0\n",
    "    sample = gibbs_sample(1).eval(session=sess, feed_dict={x: np.zeros((10, n_visible))})\n",
    "    for i in range(sample.shape[0]):\n",
    "        if not any(sample[i, :]):\n",
    "            continue\n",
    "        # Here we reshape the vector to be time x notes, and then save the vector as a midi file\n",
    "        S = np.reshape(sample[i, :], (num_timesteps, 2 * note_range))\n",
    "        midi_manipulation.noteStateMatrixToMidi(S, \"Music_Generated/generated_chord_{}\".format(i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
